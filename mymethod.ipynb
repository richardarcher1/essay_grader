{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": "base_data_path = \"data/mymethod/\"",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!ls data/mymethod",
   "id": "e546bcc4f3f67b9f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "# from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ],
   "id": "5591af65dc96a9cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, embeddings, labels):\n",
    "        # embeddings: list of numpy arrays or torch tensors\n",
    "        # labels: list of scalars\n",
    "        self.X = torch.tensor(embeddings, dtype=torch.float32)\n",
    "        self.y = torch.tensor(labels, dtype=torch.float16)  # or long, depending on your task\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ],
   "id": "56bdf2aac5b7c6d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "training_dataset = torch.load(\"data/mymethod/training.pt\")\n",
    "testing_dataset = torch.load(\"data/mymethod/testing.pt\")\n",
    "val_dataset = torch.load(\"data/mymethod/val.pt\")"
   ],
   "id": "6b765a4d5b9a2627",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(val_dataset), len(testing_dataset), len(training_dataset)",
   "id": "3aa7ea76857fac6d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Convert dataset outcomes to float32\n",
    "def convert_dataset_to_float32(dataset):\n",
    "    dataset.y = dataset.y.to(torch.float32)\n",
    "    return dataset\n",
    "\n",
    "# Convert all datasets\n",
    "training_dataset = convert_dataset_to_float32(training_dataset)\n",
    "testing_dataset = convert_dataset_to_float32(testing_dataset)\n",
    "val_dataset = convert_dataset_to_float32(val_dataset)\n"
   ],
   "id": "e55f1ac596026dbb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define a simple two-layer neural net with dropout and layer norm\n",
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(SimpleNeuralNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.layer2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n"
   ],
   "id": "5e80977cc3b1bc7a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "input_dim = int(testing_dataset.X[0].shape[0])\n",
    "hidden_dim = int(testing_dataset.X[0].shape[0]/2)"
   ],
   "id": "4b638e0aca6eb7ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = SimpleNeuralNet(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=1)\n",
    "model = model.to(\"cuda\")"
   ],
   "id": "24e3e20c0ea171bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "\n",
    "num_epochs_10 = 10\n",
    "scheduler_10 = optim.lr_scheduler.LambdaLR(\n",
    "    optimizer,\n",
    "    lr_lambda=lambda epoch: 1e-6 / 1e-3 + (1 - epoch / num_epochs_10) * (1e-3 - 1e-6) / 1e-3\n",
    ")\n",
    "\n",
    "\n",
    "num_epochs_5 = 5\n",
    "scheduler_5 = optim.lr_scheduler.LambdaLR(\n",
    "    optimizer,\n",
    "    lr_lambda=lambda epoch: 1e-6 / 1e-3 + (1 - epoch / num_epochs_5) * (1e-3 - 1e-6) / 1e-3\n",
    ")"
   ],
   "id": "c4f315cb50bafd10",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "criterion = nn.MSELoss()",
   "id": "a66813dbd2f0b6a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "num_epochs = 10",
   "id": "9c42c8e272b89baf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Prepare data loaders\n",
    "batch_size = 512\n",
    "train_loader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(testing_dataset, batch_size=batch_size, shuffle=False)\n"
   ],
   "id": "b595c2c2de42eecd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch_num in range(num_epochs):\n",
    "    \n",
    "    test_loss = 0.0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # for inputs, labels in tqdm(test_loader, desc=f\"Testing Epoch {epoch_num}\"):\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(-1), labels)\n",
    "            # test_loss += loss.item()\n",
    "            test_loss += loss.item() * inputs.size(0)  # Multiply batch loss by batch size\n",
    "        avg_loss = test_loss/len(testing_dataset)\n",
    "        test_losses.append(avg_loss)\n",
    "        print(f\"TEST LOSS: PRE Epoch-{epoch_num}, we have {avg_loss:.4f}\")\n",
    "        \n",
    "\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Training Epoch {epoch_num}\"):\n",
    "        inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        # loss = criterion(outputs, labels) # MY MSITAKE - DO NOT DO THIS\n",
    "        loss = criterion(outputs.squeeze(-1), labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # train_loss += loss.item()\n",
    "        train_loss += loss.item() * inputs.size(0)  # Multiply batch loss by batch size\n",
    "    avg_loss = train_loss/len(training_dataset) # /len(train_dataset) ?? TODO\n",
    "    train_losses.append(avg_loss)  \n",
    "    print(f\"TRAIN LOSS: On Epoch-{epoch_num}, we have {avg_loss:.4f}\")\n",
    "    scheduler_10.step()\n",
    "    # scheduler_5.step()\n",
    "        \n",
    "        "
   ],
   "id": "d04b590217f2da4f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "858bc3ff06a7f73a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plt.plot(train_losses)",
   "id": "94cfe7edf10a146b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plt.plot(test_losses)",
   "id": "7c7477e38872d15",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "30871d2f6f796277",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)",
   "id": "6d2b1c5541168ac4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "val_loss = 0.0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # for inputs, labels in tqdm(test_loader, desc=f\"Testing Epoch {epoch_num}\"):\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.squeeze(-1), labels)\n",
    "        # test_loss += loss.item()\n",
    "        val_loss += loss.item() * inputs.size(0)  # Multiply batch loss by batch size\n",
    "    avg_loss = val_loss/len(testing_dataset)\n",
    "    print(f\"ON VAL SET, ACHIEVED {avg_loss:.4f}\")"
   ],
   "id": "402409a7ef3f90b8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1ba4307cd50ee010",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f4c71ad0c33f159",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f3c1e898837f053f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "235e10d7a67ef628",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "\n",
   "id": "f5c87f5e53320772",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "942812119a61fe48",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "31499e4b71196ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "9d026d0ebb627f81",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "31ab04797e92617",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1a41f8f485a1e4d7",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
