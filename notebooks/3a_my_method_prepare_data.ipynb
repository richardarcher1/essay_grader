{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T17:28:27.102499Z",
     "start_time": "2024-12-13T17:28:25.187199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# standard python imports\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# huggingface libraries\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    LlamaForCausalLM\n",
    ")\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "from torch.utils.data import Dataset"
   ],
   "id": "82b0c813102028da",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T17:28:27.110423Z",
     "start_time": "2024-12-13T17:28:27.108531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_prompt(review):\n",
    "    system_prompt = f\"You read student essays reviews and return a score from 0 to 60 that represents your besst guess of the number of rating given by the grader. Return just the number 0, 1, ..., 60 with no context, explanation, or special symbols.\"\n",
    "    prompt = f\"Here is the review to evaluate: [[[{review}]]]. You read student essays reviews and return a score from 0 to 60 that represents your besst guess of the number of rating given by the grader. Return just the number 0, 1, ..., 60 with no context, explanation, or special symbols.\"\n",
    "\n",
    "    return system_prompt, prompt\n"
   ],
   "id": "2bb3dfe2a773bb0d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T17:28:27.177096Z",
     "start_time": "2024-12-13T17:28:27.175759Z"
    }
   },
   "cell_type": "code",
   "source": "base_model = \"../models/llama_base/snapshots/0e9e39f249a16976918f6564b8830bc894c89659\"",
   "id": "73dc2335debb08d3",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T17:28:27.219795Z",
     "start_time": "2024-12-13T17:28:27.218030Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_prompts_to_df(df):\n",
    "    lst_system_prompt, lst_prompt = [], []\n",
    "    for row in df.iter_rows(named=True):\n",
    "        system_prompt, prompt = create_prompt(row[\"text\"])\n",
    "        lst_system_prompt.append(system_prompt)\n",
    "        lst_prompt.append(prompt)\n",
    "    df = df.with_columns(pl.Series(lst_system_prompt).alias(\"system_prompt\"), pl.Series(lst_prompt).alias(\"prompt\"))\n",
    "    return df"
   ],
   "id": "891f40437ef516fa",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T17:28:27.264113Z",
     "start_time": "2024-12-13T17:28:27.261744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, embeddings, labels):\n",
    "        # embeddings: list of numpy arrays or torch tensors\n",
    "        # labels: list of scalars\n",
    "        self.X = torch.tensor(embeddings, dtype=torch.float32)\n",
    "        self.y = torch.tensor(labels, dtype=torch.float32)  # or long, depending on your task\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ],
   "id": "f53f2b013dfd3263",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T17:28:27.309309Z",
     "start_time": "2024-12-13T17:28:27.306569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def df_to_dataset(df, batch_size, model, tokenizer):\n",
    "    model.eval()\n",
    "\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "\n",
    "    rows = df.to_dicts()  # returns a list of row dictionaries\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(df), batch_size)):\n",
    "            # if i % (batch_size * 1_000) == 0:\n",
    "            #     print(f\"CURRENTLY OPERATING ON IX={i}/{len(df)}\")\n",
    "            #     wandb.log({\"ix\": i})\n",
    "            batch_rows = rows[i: i + batch_size]\n",
    "\n",
    "            # Prepare batched input\n",
    "            batch_messages = [\n",
    "                [\n",
    "                    {\"role\": \"system\", \"content\": r[\"system_prompt\"]},\n",
    "                    {\"role\": \"user\", \"content\": r[\"prompt\"]}\n",
    "                ]\n",
    "                for r in batch_rows\n",
    "            ]\n",
    "\n",
    "            # Tokenize the entire batch at once\n",
    "            inputs_message = tokenizer.apply_chat_template(\n",
    "                batch_messages,\n",
    "                add_generation_prompt=True,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=True,\n",
    "                truncation=True\n",
    "            ).to(\"cuda\")\n",
    "\n",
    "            # Single forward pass for the entire batch\n",
    "            with torch.no_grad():\n",
    "                outputs = model(\n",
    "                    inputs_message,\n",
    "                    output_hidden_states=True,\n",
    "                    return_dict=True\n",
    "                )\n",
    "            # Extract embeddings for the entire batch at once\n",
    "            hidden_states = outputs.hidden_states\n",
    "            # Convert to float32 before moving to CPU and then NumPy\n",
    "            embeddings_batch = hidden_states[-2][:, -1, :].to(dtype=torch.float32).cpu().numpy()\n",
    "\n",
    "            # Add them to a growing list\n",
    "            for j, r in enumerate(batch_rows):\n",
    "                embeddings.append(embeddings_batch[j])\n",
    "                labels.append(r[\"score\"])\n",
    "\n",
    "        # Convert to a Dataset\n",
    "        dataset = CustomDataset(np.array(embeddings), labels)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "57932e62bb68e008",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T17:28:34.256413Z",
     "start_time": "2024-12-13T17:28:27.350999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model,\n",
    "    tokenizer_file=os.path.join(base_model, 'tokenizer.json'),\n",
    "    tokenizer_config_file=os.path.join(base_model, 'tokenizer_config.json'),\n",
    "    special_tokens_map_file=os.path.join(base_model, 'special_tokens_map.json'),\n",
    "    trust_remote_code=True,\n",
    "    padding_side='left'\n",
    ")\n",
    "\n",
    "tokenizer.padding_side = 'left'\n",
    "\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    # load_in_8bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,  # Match input dtype\n",
    "\n",
    ")\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained(base_model, quantization_config=nf4_config)\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     base_model,\n",
    "#     device_map=\"auto\",\n",
    "#     # device_map=\"balanced\",\n",
    "#     torch_dtype=torch.bfloat16\n",
    "# )\n",
    "\n",
    "if not tokenizer.pad_token_id:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "if model.config.pad_token_id is None:\n",
    "    model.config.pad_token_id = model.config.eos_token_id\n",
    "\n"
   ],
   "id": "949f4f384faca4bc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d27f353e0f9b4f6c8049b1b4b03ade7d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T17:29:18.998649Z",
     "start_time": "2024-12-13T17:28:34.269951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_val = pl.read_csv(\"../data/1_clean/val.csv\")\n",
    "\n",
    "df_val = add_prompts_to_df(df_val)\n",
    "\n",
    "dataset_val = df_to_dataset(df=df_val, batch_size=4, model=model, tokenizer=tokenizer)\n",
    "\n",
    "torch.save(dataset_val, \"../data/2_ready_for_training/mymethod/val.pt\")"
   ],
   "id": "65326b7cf159f5e9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:44<00:00,  3.50it/s]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T17:31:37.179034Z",
     "start_time": "2024-12-13T17:29:19.017802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_testing = pl.read_csv(\"../data/1_clean/testing.csv\")\n",
    "\n",
    "df_testing = add_prompts_to_df(df_testing)\n",
    "\n",
    "dataset_testing = df_to_dataset(df=df_testing, batch_size=4, model=model, tokenizer=tokenizer)\n",
    "\n",
    "torch.save(dataset_testing, \"../data/2_ready_for_training/mymethod/testing.pt\")"
   ],
   "id": "37b1f12db666690f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 488/488 [02:18<00:00,  3.53it/s]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T17:43:49.063946Z",
     "start_time": "2024-12-13T17:31:37.203921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_training = pl.read_csv(\"../data/1_clean/training.csv\")\n",
    "\n",
    "df_training = add_prompts_to_df(df_training)\n",
    "\n",
    "dataset_training = df_to_dataset(df=df_training, batch_size=4, model=model, tokenizer=tokenizer)\n",
    "\n",
    "torch.save(dataset_training, \"../data/2_ready_for_training/mymethod/training.pt\")"
   ],
   "id": "80593ea542136300",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2601/2601 [12:11<00:00,  3.56it/s]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T17:43:49.084726Z",
     "start_time": "2024-12-13T17:43:49.083509Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "839531cf4389c7b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T17:43:49.126098Z",
     "start_time": "2024-12-13T17:43:49.124897Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e900b20409181201",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T17:43:49.169146Z",
     "start_time": "2024-12-13T17:43:49.168009Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "c81b8554b67756fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T17:43:49.211959Z",
     "start_time": "2024-12-13T17:43:49.210820Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "1263a57eb20b49f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T17:43:49.255977Z",
     "start_time": "2024-12-13T17:43:49.254794Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "afb7c98d9eaed91f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
