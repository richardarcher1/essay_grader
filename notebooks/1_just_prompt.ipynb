{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T16:33:34.236436Z",
     "start_time": "2024-12-13T16:33:32.340429Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# standard python imports\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# huggingface libraries\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    pipeline,\n",
    "    LlamaForCausalLM\n",
    ")\n",
    "# from peft import (\n",
    "#     LoraConfig,\n",
    "#     PeftModel,\n",
    "#     prepare_model_for_kbit_training,\n",
    "#     get_peft_model,\n",
    "# )\n",
    "\n",
    "from datasets import Dataset # NOTE: this is NOT the torch dataset type, which can cause confusion\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error"
   ],
   "id": "3df504892b84836",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T16:33:34.244329Z",
     "start_time": "2024-12-13T16:33:34.242743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_prompt(review):\n",
    "    system_prompt = f\"You read student essays reviews and return a score from 0 to 60 that represents your besst guess of the number of rating given by the grader. Return just the number 0, 1, ..., 60 with no context, explanation, or special symbols.\"\n",
    "    prompt = f\"Here is the review to evaluate: [[[{review}]]]. You read student essays reviews and return a score from 0 to 60 that represents your besst guess of the number of rating given by the grader. Return just the number 0, 1, ..., 60 with no context, explanation, or special symbols.\"\n",
    "\n",
    "    return system_prompt, prompt\n"
   ],
   "id": "1f199aff9cda8d9f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T16:33:34.328915Z",
     "start_time": "2024-12-13T16:33:34.310254Z"
    }
   },
   "cell_type": "code",
   "source": "df_val = pl.read_csv(\"../data/1_clean/val.csv\")",
   "id": "4417d92b8ecba748",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T16:33:34.373938Z",
     "start_time": "2024-12-13T16:33:34.353303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lst_system_prompt, lst_prompt = [], []\n",
    "for row in df_val.iter_rows(named=True):\n",
    "    system_prompt, prompt = create_prompt(row[\"text\"])\n",
    "    lst_system_prompt.append(system_prompt)\n",
    "    lst_prompt.append(prompt)\n",
    "df_val = df_val.with_columns(pl.Series(lst_system_prompt).alias(\"system_prompt\"), pl.Series(lst_prompt).alias(\"prompt\"))"
   ],
   "id": "f942fe169ec1001b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T16:33:34.416236Z",
     "start_time": "2024-12-13T16:33:34.402548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_texts = df_val[\"text\"].to_list()\n",
    "test_labels = df_val[\"score\"].to_list()\n",
    "\n",
    "data_ = Dataset.from_polars(df_val)"
   ],
   "id": "6b4195b3c84f2c7e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T16:33:34.452592Z",
     "start_time": "2024-12-13T16:33:34.451313Z"
    }
   },
   "cell_type": "code",
   "source": "base_model = \"../models/llama_base/snapshots/0e9e39f249a16976918f6564b8830bc894c89659\"",
   "id": "45ca423565fc923f",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T16:33:34.750018Z",
     "start_time": "2024-12-13T16:33:34.498932Z"
    }
   },
   "cell_type": "code",
   "source": "!ls ../models/llama_base/snapshots/0e9e39f249a16976918f6564b8830bc894c89659",
   "id": "50ffb8e77a456a1f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json\t\t\t  model.safetensors.index.json\r\n",
      "generation_config.json\t\t  original\r\n",
      "LICENSE\t\t\t\t  README.md\r\n",
      "model-00001-of-00004.safetensors  special_tokens_map.json\r\n",
      "model-00002-of-00004.safetensors  tokenizer_config.json\r\n",
      "model-00003-of-00004.safetensors  tokenizer.json\r\n",
      "model-00004-of-00004.safetensors  USE_POLICY.md\r\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T16:33:34.965326Z",
     "start_time": "2024-12-13T16:33:34.755172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model,\n",
    "    tokenizer_file=os.path.join(base_model, 'tokenizer.json'),\n",
    "    tokenizer_config_file=os.path.join(base_model, 'tokenizer_config.json'),\n",
    "    special_tokens_map_file=os.path.join(base_model, 'special_tokens_map.json'),\n",
    "    trust_remote_code=True,\n",
    "    padding_side='left'\n",
    ")\n",
    "\n",
    "tokenizer.padding_side = 'left'"
   ],
   "id": "1add9a0e94742ed2",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T16:33:42.844124Z",
     "start_time": "2024-12-13T16:33:34.975600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nf4_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    # load_in_8bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,  # Match input dtype\n",
    "\n",
    ")\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained(base_model, quantization_config=nf4_config)"
   ],
   "id": "17ab72742719d66f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8f606d84bc0c45fba3eeb1dbe40f915a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T16:33:42.858839Z",
     "start_time": "2024-12-13T16:33:42.857669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# model = PeftModel.from_pretrained(model, PATH_adapter_custom_weights)\n",
    "# model = model.merge_and_unload() # This line merges the weights"
   ],
   "id": "e313bbcca906864c",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T16:33:42.900737Z",
     "start_time": "2024-12-13T16:33:42.899229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if not tokenizer.pad_token_id:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "if model.config.pad_token_id is None:\n",
    "    model.config.pad_token_id = model.config.eos_token_id"
   ],
   "id": "abbb18ad1c5dd048",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T16:33:42.943945Z",
     "start_time": "2024-12-13T16:33:42.942397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def remove_header(text, K_times):\n",
    "    for _ in range(K_times):\n",
    "        if \"<|end_header_id|>\" in text:\n",
    "            text = text.split(\"<|end_header_id|>\", 1)[1]\n",
    "    return text"
   ],
   "id": "220a0c1f1d26060e",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T16:33:42.987474Z",
     "start_time": "2024-12-13T16:33:42.985709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_format_chat_template(tokenizer):\n",
    "    def format_chat_template(row):\n",
    "        row_json = [{\"role\": \"system\", \"content\": row[\"system_prompt\"]},\n",
    "                    {\"role\": \"user\", \"content\": row[\"prompt\"]}]\n",
    "\n",
    "        # row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)\n",
    "        row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False, add_generation_prompt=True)\n",
    "        return row\n",
    "    return format_chat_template"
   ],
   "id": "3c4d25e2c768cfea",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T16:33:43.030865Z",
     "start_time": "2024-12-13T16:33:43.029373Z"
    }
   },
   "cell_type": "code",
   "source": "batch_size = 8",
   "id": "98829e0291217c35",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T16:33:43.074363Z",
     "start_time": "2024-12-13T16:33:43.072422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    # torch_dtype=torch.float32,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    batch_size=batch_size, # CHANGE TO FOUR IF TOO SLOW\n",
    "    max_new_tokens=5,\n",
    ")"
   ],
   "id": "e50b8d130804c758",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T16:33:43.229288Z",
     "start_time": "2024-12-13T16:33:43.116907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_ = data_.map(\n",
    "    create_format_chat_template(tokenizer)\n",
    ")"
   ],
   "id": "ae6463a48d38633c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/622 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "14b2fd7bb1a04671a6c91ca07e6a6dd6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T16:34:41.020987Z",
     "start_time": "2024-12-13T16:33:43.242089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res = []\n",
    "ix = 0\n",
    "for out in pipe(KeyDataset(data_, \"text\")):\n",
    "    ix = ix + 1\n",
    "    if ix % batch_size == 0:\n",
    "        print(f\"{ix}/{data_.shape[0]}\")\n",
    "\n",
    "    cleaned_text = remove_header(out[0][\"generated_text\"], 3).strip()\n",
    "    res.append(cleaned_text)"
   ],
   "id": "bce3924294b12d32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/622\n",
      "16/622\n",
      "24/622\n",
      "32/622\n",
      "40/622\n",
      "48/622\n",
      "56/622\n",
      "64/622\n",
      "72/622\n",
      "80/622\n",
      "88/622\n",
      "96/622\n",
      "104/622\n",
      "112/622\n",
      "120/622\n",
      "128/622\n",
      "136/622\n",
      "144/622\n",
      "152/622\n",
      "160/622\n",
      "168/622\n",
      "176/622\n",
      "184/622\n",
      "192/622\n",
      "200/622\n",
      "208/622\n",
      "216/622\n",
      "224/622\n",
      "232/622\n",
      "240/622\n",
      "248/622\n",
      "256/622\n",
      "264/622\n",
      "272/622\n",
      "280/622\n",
      "288/622\n",
      "296/622\n",
      "304/622\n",
      "312/622\n",
      "320/622\n",
      "328/622\n",
      "336/622\n",
      "344/622\n",
      "352/622\n",
      "360/622\n",
      "368/622\n",
      "376/622\n",
      "384/622\n",
      "392/622\n",
      "400/622\n",
      "408/622\n",
      "416/622\n",
      "424/622\n",
      "432/622\n",
      "440/622\n",
      "448/622\n",
      "456/622\n",
      "464/622\n",
      "472/622\n",
      "480/622\n",
      "488/622\n",
      "496/622\n",
      "504/622\n",
      "512/622\n",
      "520/622\n",
      "528/622\n",
      "536/622\n",
      "544/622\n",
      "552/622\n",
      "560/622\n",
      "568/622\n",
      "576/622\n",
      "584/622\n",
      "592/622\n",
      "600/622\n",
      "608/622\n",
      "616/622\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T16:34:41.039439Z",
     "start_time": "2024-12-13T16:34:41.037589Z"
    }
   },
   "cell_type": "code",
   "source": "res_int = [int(i) for i in res]",
   "id": "9b6e7a8eb703c0b9",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T16:34:41.094226Z",
     "start_time": "2024-12-13T16:34:41.092811Z"
    }
   },
   "cell_type": "code",
   "source": "llm_predicted, true_values = np.array(res_int), np.array(test_labels)",
   "id": "4c9abba4e065118f",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T16:34:41.137309Z",
     "start_time": "2024-12-13T16:34:41.134495Z"
    }
   },
   "cell_type": "code",
   "source": "test_mse = mean_squared_error(llm_predicted, true_values)",
   "id": "9b6e3a186b9e042",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T16:35:13.932585Z",
     "start_time": "2024-12-13T16:35:13.930741Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Test MSE: {test_mse:,.2f}\")",
   "id": "284352bd88b6b3c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1,020.89\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T16:34:41.197363Z",
     "start_time": "2024-12-13T16:34:41.192381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_val = df_val.with_columns(pl.Series(res_int).alias(\"8b_quant_prediction\"))\n",
    "df_val.write_csv(\"../outputs/predictions/8b_quantized_base.csv\")"
   ],
   "id": "3d3ff8735f99ea04",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T16:36:44.771680Z",
     "start_time": "2024-12-13T16:36:44.770407Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e29756dbd5376d6e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
